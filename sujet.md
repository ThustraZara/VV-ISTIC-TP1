# Practical Session #1: Introduction

1. Find in news sources a general public article reporting the discovery of a software bug. Describe the bug. If possible, say whether the bug is local or global and describe the failure that manifested its presence. Explain the repercussions of the bug for clients/consumers and the company or entity behind the faulty program. Speculate whether, in your opinion, testing the right scenario would have helped to discover the fault.

2. Apache Commons projects are known for the quality of their code and development practices. They use dedicated issue tracking systems to discuss and follow the evolution of bugs and new features. The following link https://issues.apache.org/jira/projects/COLLECTIONS/issues/COLLECTIONS-794?filter=doneissues points to the issues considered as solved for the Apache Commons Collections project. Among those issues find one that corresponds to a bug that has been solved. Classify the bug as local or global. Explain the bug and the solution. Did the contributors of the project add new tests to ensure that the bug is detected if it reappears in the future?

3. Netflix is famous, among other things we love, for the popularization of *Chaos Engineering*, a fault-tolerance verification technique. The company has implemented protocols to test their entire system in production by simulating faults such as a server shutdown. During these experiments they evaluate the system's capabilities of delivering content under different conditions. The technique was described in [a paper](https://arxiv.org/ftp/arxiv/papers/1702/1702.05843.pdf) published in 2016. Read the paper and briefly explain what are the concrete experiments they perform, what are the requirements for these experiments, what are the variables they observe and what are the main results they obtained. Is Netflix the only company performing these experiments? Speculate how these experiments could be carried in other organizations in terms of the kind of experiment that could be performed and the system variables to observe during the experiments.

4. [WebAssembly](https://webassembly.org/) has become the fourth official language supported by web browsers. The language was born from a joint effort of the major players in the Web. Its creators presented their design decisions and the formal specification in [a scientific paper](https://people.mpi-sws.org/~rossberg/papers/Haas,%20Rossberg,%20Schuff,%20Titzer,%20Gohman,%20Wagner,%20Zakai,%20Bastien,%20Holman%20-%20Bringing%20the%20Web%20up%20to%20Speed%20with%20WebAssembly.pdf) published in 2018. The goal of the language is to be a low level, safe and portable compilation target for the Web and other embedding environments. The authors say that it is the first industrial strength language designed with formal semantics from the start. This evidences the feasibility of constructive approaches in this area. Read the paper and explain what are the main advantages of having a formal specification for WebAssembly. In your opinion, does this mean that WebAssembly implementations should not be tested? 

5.  Shortly after the appearance of WebAssembly another paper proposed a mechanized specification of the language using Isabelle. The paper can be consulted here: https://www.cl.cam.ac.uk/~caw77/papers/mechanising-and-verifying-the-webassembly-specification.pdf. This mechanized specification complements the first formalization attempt from the paper. According to the author of this second paper, what are the main advantages of the mechanized specification? Did it help improving the original formal specification of the language? What other artifacts were derived from this mechanized specification? How did the author verify the specification? Does this new specification removes the need for testing?

## Answers

1.

Source #1: https://www.bleepingcomputer.com/news/security/hackers-exploit-bug-in-wordpress-gift-card-plugin-with-50k-installs/
Source #2: https://nvd.nist.gov/vuln/detail/CVE-2022-45359

  The subject of the above-mentioned news article describes a vulnerability found in a WordPress plug-in used to sell online gift cards. This is a local vulnerability that affected roughly 50,000 sites that used the said plug-in.
  The vulnerability lies inside a function called 'import_actions_from_settings_panel', which runs on the 'admin_init' hook (a function called every time an admin panel is initialized). This vulnerability is due to a lack of CSRF checks (Cross-Site Request Forgery); this type of security mechanism has the role of checking that a request comes from an authorized source. This means that malicious actors, who do not have the adequat permissions, could send a request to this function and take actions that, in theory, are not permited for the said individual and, therefore, gain almost full access to the infrastructure of the sites that use this plug-in.
Despite it affecting 50,000 sites, this is a local vulnerability, since it does not give access to other parts of the WordPress' infrastructure.
_________________________________________________________________________________________________________________________________________________________________

2.

Source #1: https://issues.apache.org/jira/projects/COLLECTIONS/issues/COLLECTIONS-796?filter=doneissues
Source #2: https://github.com/apache/commons-collections/commit/b1c45ac691d46a8c609f2534d2adfa59c0599527#diff-8e53271d5d8299a76d43b0e3c81740fbe660083ae71c5bf2be63846d52156f23L344

  The following is a bug that is due to a deprecated method called 'createSetBasedOnList()'. This function was used to create a Set of the data type given as a parameter, with elements from a pre-existing List, which was also given as function input. A developer discovered that this function returned an empty set; this was due to an accidental deletion of an 'addAll()' call. While rectifying this bug, the developer also chose to add the use of 'getDelcaredConstructor()' function every time 'newInstance()' method was called, which added an additional layer of security and control over the data-structure instantiation. 
  On the first look, this bug seems to be a local one, since it would not directly give access to the outside of the used method or class; however, the unpredictable behaviour that this bug might cause could potentially be used by mal-intentioned individuals so as to bypass security checks, if the latter would use the aforementioned function. Therefore, the classification of this bug  as local or global would depend upon the use of this method (i.e., if this method was to be used in security verifications).
  The bug-fix was not followed by the addition of new tests, and therefore would not be flagged if the bug re-appeared post factum. However, the change was documented in the 'changes.xml' file, which, I assume, is a file who's role is to keep all the changes that are made in that project.
_________________________________________________________________________________________________________________________________________________________________

3.

  'Chaos Engineering' is a form of testing the robustness of a service (such as Netflix) by simulating real-world problems that could occur during production; this type of errors include the failure of one of the regional servers that host the service, delaying the response time for the incoming requests, or even completely disabling one of the microservices of the overall system. There are 4 steps necessary for this kind of test: finding a metric that represents the quality of the service, deciding upon system fault to be injected/simulated, introducing said fault and comparing the results between the control group and the experimental group, and finally a seemless rollback to the original version.
  The role of the previously mentioned metric of quality is to quantify "how well the system behaves" (known internally at Netflix as 'steady-state behaviour'). In the case of Netflix, the metric they use is called SPS, or 'streams per second' (i.e., how many users are launching a stream every second). Another metric that is used in this company is 'sign-ups per second', but we will focus on SPS. This metric lets the engineers at Netflix to establish the quality of the service (also called the 'availability' of the service). 
  Once the metric is established, the engineers decide upon what kind of failure to inject or simulate in order to test the service. One of the system fault that are commonly injected/simulated is the shutdown of one of the regional servers (since the Netflix`s infrastructure and client base is so big, the whole service cannot be hosted by only one server), the disabling of the communication between two microservices, etc. Netflix engineers can also choose to simulate the fault for a subset of their users, so as to not deteriorate the quality of the service for all the users. In any case, what they do is separate the users into two groups (control and experimental), inject/simulate the fault for the experimental group and watch the difference in SPS between the two groups. The initial hypothesis is that the degradation of the service will yield an inconsiderable difference between the SPS of the two groups and, therefore, prove the robustness of the service. However, if there is a non-negligible difference, the experiment is stopped prematurely and a plan for solving the issue is created. 
  As mentioned in the paper, 'Chaos Engineering' is not used exclusively by Netflix (such companies like Google, Amazon and Microsoft are also mentioned). This type of experiments could be adapted for any big service provider (especially for distributed-systems) so as to test the quality of the service. The system faults mentioned in the paper are not exclusive to video streaming services, they might as well be used in other projects (faults like delaying the reponse for requests, cutting the communication channel between micro-services, etc, are problems that can be encountered in pretty much all the big projects). The bigger difference that should be taken in consideration is the metric of the quality of the service that can vary from one service to another. The real challenge of 'Chaos Engineering' is the fact that it has to take place after the service is being deployed: the management of fault injection and the capability to easily roll-back to a stable version is crucial for keeping an overall good quality of the service, so as to not degrade the experience of the users, all the while being able to test the steadyness of the system.
_________________________________________________________________________________________________________________________________________________________________

4.

  First of all, the choice of building this Web programming language based on a formal syntax from the very start offers an ease of read and decoding without compromising the compactness/tightness, a feature necessary for the portability of the language as well as the good performance and security. The formal syntax offers the possibility for developpers to easily read, understand and write WebAssembly code, while forcing a structured/deterministic code (structured in terms of the lack of 'gotos' that are commonly used by bad actors in order to bypass certain safety checks and force the program to behave in an unexpected -- and often undesirable -- way). For example, the structure of the abstract grammar that this language is based doesn't allow the developer to stack branchings which makes it impossible to insert jumps-to-jumps inside the code, a technique that could be used for mal-intended purposes. 
  Defining an abstract syntax with simple data-types and instructions (both of which are found on all platforms and operating systems) allowed them to create a language that is highly portable (i.e., hardware/platform independent) and offers a level of compactness that makes the code lightweight and easy to compile and execute; coupled with an ingenious way of separating all the data and control stacks so as to encapsulate the execution of all the programs; in other words: preventing modules and functions to interfere with the execution of other functions/modules, which, in term, drastically increases the security of the language.
  However, the fact that WebAssembly is highly secured does not mean that tests aren't necessary: preventing malicious behaviour does not automatically mean that the language is secured against stupid or inattentive developers. The architecture of this language prevents functions/modules from interfering with the execution of its other parts, but mistakes might very well be made inside the same function or module. 
_________________________________________________________________________________________________________________________________________________________________

5.

  The use of mechanized specification allowed researchers to detect security vulnerabilities in terms of data type, 'Trap' propagation (a sort of 'Exception'), unintended use of the 'Return' operation, etc. While adapting the abstract syntax so as to be checked with IsabelleHOL (a proof assistant that uses logic in order to prove the correct behaviour of a program) and proving the whole syntax of WebAssembly, they have established that the grammar wasn't sound and needed a few changes in order to guarantee the correct behaviour of programs written in this language. The presence of said vulnerabilities in the original syntax of WebAssembly (despite the enormous effort from its creators) is not surprising; spotting such logical imperfections can be extremely challenging for a human being. This only shows the power of proof assistants like Isabelle, that are capable to spot contradictions or create counter-examples for a given theory through the use of logic and smart algorithms. The mechanized specification allowed both the creators of WebAssembly (as well as the researchers that tried to improve the programming language) to improve and perfect the abstract syntax in order to guarantee the expected behaviour from programs written in this language, as well as developing an executable type checker and interpreter, which can be used in dynamic validation of programs coded in WebAssembly. This is a feature that is not implemented in WA (at least, as of the writing of this paper), and, by extension, cannot be used to validate programs. 
  The use of the mechanized specification does not remove the need for testing, it only serves for the validation of the new model (i.e., the correct behaviour and level of security of programs written in WebAssembly). Once again, this does not protect the programs for human-made errors and, thus, still demands the use of tests in order to prove the correct implementation of the desired service.